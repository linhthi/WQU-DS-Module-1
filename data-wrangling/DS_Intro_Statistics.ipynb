{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib\n",
    "import seaborn as sns\n",
    "matplotlib.rcParams['savefig.dpi'] = 144"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction to Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics is the study of how random variables behave in aggregate. It is also the use of that behavior to make inferences and arguments. While much of the math behind statistical calculations is rigorous and precise, its application to real data often involves making imperfect assumptions. In this notebook we will review some fundamental statistics and pay special attention to the assumptions we make in their application."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing and Parameter Estimator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We often use statistics to describe groups of people or events; for example we compare the current temperature to the *average* temperature for the day or season or we compare a change in stock price to the *volatility* of the stock (in the language of statistics, volatility is called **standard deviation**) or we might wonder what the *average* salary of a data scientist is in a particular country. All of these questions and comparisons are rudimentary forms of statistical inference. Statistical inference often falls into one of two categories: hypothesis testing or parameter estimator.\n",
    "\n",
    "Examples of hypothesis testing are:\n",
    "- Testing if an increase in a stock's price is significant or just random chance\n",
    "- Testing if there is a significant difference in salaries between employees with and without advanced degrees\n",
    "- Testing whether there is a significant correlation between the amount of money a customer spent at a store and which advertisements they'd been shown\n",
    "\n",
    "Examples of parameter estimation are:\n",
    "- Estimating the average annual return of a stock\n",
    "- Estimating the variance of salaries for a particular job across companies\n",
    "- Estimating the correlation coefficient between annual advertising budget and annual revenue\n",
    "\n",
    "We'll explore the processes of statistical inference by considering the example of salaries with and without advanced degrees.\n",
    "\n",
    "**Exercise:** Decide for each example given in the first sentence whether it is an example of hypothesis testing or parameter estimation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Estimating the Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose that we know from a prior study that employees with advanced degrees in the USA make on average $70k. To answer the question \"do people without advanced degrees earn significantly less than people with advanced degrees?\" we must first estimate how much people without advanced degrees earn on average.\n",
    "\n",
    "To do that, we will have to collect some data. Suppose we take a representative, unbiased sample of 1000 employed adults without advanced degrees and learn their salaries. To estimate the mean salary of people without advanced degrees, we simply calculate the mean of this sample:\n",
    "\n",
    "$$ \\overline X = \\frac{1}{n} \\sum_{k=1}^n X_k. $$\n",
    "\n",
    "Let's write some code that will simulate sampling some salaries for employees without advanced degrees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, IntSlider\n",
    "\n",
    "salaries = sp.stats.lognorm(1, loc=20, scale=25)\n",
    "\n",
    "def plot_sample(dist):\n",
    "    def plotter(size):\n",
    "        X = dist.rvs(size=size)\n",
    "        ys, bins, _ = plt.hist(X, bins=20, normed=True)\n",
    "        plt.ylim([0, ys.max() / (ys * (bins[1] - bins[0])).sum() * 1.25])\n",
    "        plt.axvline(dist.mean(), color='r', label='true mean')\n",
    "        plt.axvline(X.mean(), color='g', label='sample mean')\n",
    "        plt.plot(np.arange(20, 100, .01), salaries.pdf(np.arange(20, 100, .01)), 'k--')\n",
    "        plt.legend()\n",
    "\n",
    "    return plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size_slider = IntSlider(min=10, max=200, step=10, value=10, description='sample size')\n",
    "interact(plot_sample(salaries), size=sample_size_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standard Error of the Mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that each time we run the code to generate the plot above, we draw a different sample. While the \"true\" mean remains fixed, the sample mean changes as we draw new samples. In other words, our estimate (the sample mean) of the true mean is noisy and has some error. How noisy is it? How much does it typically differ from the true mean? *What is the **standard deviation** of the sample mean from the true mean*?\n",
    "\n",
    "Let's take many samples and make a histogram of the sample means to visualize the typical difference between the sample mean and the true mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sampling_dist(dist):\n",
    "    def plotter(sample_size):\n",
    "        means = np.array([dist.rvs(size=sample_size).mean() for _ in range(300)]) - dist.mean()\n",
    "        plt.hist(means, bins=20, normed=True, label='sample means')\n",
    "\n",
    "        # plot central limit theorem distribution\n",
    "        Xs = np.linspace(means.min(), means.max(), 1000)\n",
    "        plt.plot(Xs, sp.stats.norm.pdf(Xs, scale=np.sqrt(dist.var()/sample_size)), 'k--',\n",
    "                 label='central limit theorem')\n",
    "\n",
    "        plt.legend()\n",
    "\n",
    "    return plotter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_size_slider = IntSlider(min=10, max=500, step=10, value=10, description='sample size')\n",
    "interact(plot_sampling_dist(salaries),\n",
    "         sample_size=sample_size_slider)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we increase the size of our samples, the distribution of sample means comes to resemble a normal distribution. In fact this occurs regardless of the underlying distribution of individual salaries. This phenomenon is described by the Central Limit Theorem, which states that as the sample size increases, the sample mean will tend to follow a normal distribution with a standard deviation\n",
    "\n",
    "$$ \\sigma_{\\overline X} = \\sqrt{\\frac{\\sigma^2}{n}}.$$\n",
    "\n",
    "This quantity is called the **standard error**, and it quantifies the standard deviation of the sample mean from the true mean.\n",
    "\n",
    "**Exercise:** In your own words, explain the difference between the standard deviation and the standard error of salaries in our example."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hypothesis Testing and z-scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we can calculate how much we may typically expect the sample mean to differ from the true mean by random chance, we can perform a **hypothesis test**. In hypothesis testing, we assume that the true mean is a known quantity. We then collect a sample and calculate the difference between the sample mean and the assumed true mean. If this difference is large compared to the standard error (i.e. the typical difference we might expect to arise from random chance), then we conclude that the true mean is unlikely to be the value that we had assumed. Let's be more precise with out example.\n",
    "\n",
    "1. Suppose that we know from a prior study that employees with advanced degrees in the USA make on average \\$70k. Our **null hypothesis** will be that employees without advanced degrees make the same salary: $H_0: \\mu = 70$. We will also choose a threshold of significance for our evidence. In order to decide that our null hypothesis is wrong, we must find evidence that would have less than a certain probability $\\alpha$ of occurring due to random chance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = 70"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Next we collect a sample of salaries from $n$ employees without advanced degrees and calculate the mean of the sample salaries. Below we'll sample 100 employees."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_salaries = salaries.rvs(size=100)\n",
    "print('Sample mean: {}'.format(sample_salaries.mean()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Now we compare the difference between the sample mean and the assumed true mean to the standard error. This quantity is called a **z-score**.\n",
    "\n",
    "$$ z = \\frac{\\overline X - \\mu}{\\sigma / \\sqrt{n}} $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "z = (sample_salaries.mean() - mu) / np.sqrt(salaries.var() / sample_salaries.size)\n",
    "print('z-score: {}'.format(z))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. The z-score can be used with the standard normal distribution (due to the Central Limit Theorem) to calculate the probability that the difference between the sample mean and the null hypothesis is due only to random chance. This probability is called a **p-value**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = sp.stats.norm.cdf(z)\n",
    "print('p-value: {}'.format(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(211)\n",
    "stderr = np.sqrt(salaries.var() / sample_salaries.size)\n",
    "Xs = np.linspace(mu - 3*stderr, mu + 3*stderr, 1000)\n",
    "clt = sp.stats.norm.pdf(Xs, loc=mu, scale=stderr)\n",
    "plt.plot(Xs, clt, 'k--',\n",
    "         label='central limit theorem')\n",
    "plt.axvline(sample_salaries.mean(), color='b', label='sample mean')\n",
    "plt.fill_between(Xs[Xs < mu - 2*stderr], 0, clt[Xs < mu - 2*stderr], color='r', label='critical region')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(212)\n",
    "Xs = np.linspace(-3, 3, 1000)\n",
    "normal = sp.stats.norm.pdf(Xs)\n",
    "plt.plot(Xs, normal, 'k--', label='standard normal distribution')\n",
    "plt.axvline(z, color='b', label='z-score')\n",
    "plt.fill_between(Xs[Xs < -2], 0, normal[Xs < -2], color='r', label='critical region')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. If our p-value is less than $\\alpha$ then we can reject the null hypothesis; since we found evidence that was very unlikely to arise by random chance, it must be that our initial assumption about the value of the true mean was wrong.\n",
    "\n",
    "This is a very simplified picture of hypothesis testing, but the central idea can be a useful tool outside of the formal hypothesis testing framework. By calculating the difference between an observed quantity and the value we would expect, and then comparing this difference to our expectation for how large the difference might be due to random chance, we can quickly make intuitive judgments about quantities that we have measured or calculated."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Confidence Intervals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also use the Central Limit Theorem to help us perform parameter estimation. Using our sample mean, we estimate the average salary of employees without advanced degrees. However, we also know that this estimate deviates somewhat from the true mean due to the randomness of our sample. Therefore we should put probabilistic bounds on our estimate. We can again use the standard error to help us calculate this probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Confidence interval (95%) for average salary: ({:.2f} {:.2f})\".format(sample_salaries.mean() - 2 * stderr,\n",
    "                                                                             sample_salaries.mean() + 2 * stderr))\n",
    "\n",
    "Xs = np.linspace(sample_salaries.mean() - 3*stderr,\n",
    "                 sample_salaries.mean() + 3*stderr,\n",
    "                 1000)\n",
    "ci = sp.stats.norm.pdf(Xs, loc=sample_salaries.mean(), scale=stderr)\n",
    "plt.plot(Xs, ci, 'k--',\n",
    "         label='confidence interval pdf')\n",
    "plt.fill_between(Xs[(Xs > sample_salaries.mean() - 2*stderr) & (Xs < sample_salaries.mean() + 2*stderr)],\n",
    "                 0,\n",
    "                 clt[(Xs > sample_salaries.mean() - 2*stderr) & (Xs < sample_salaries.mean() + 2*stderr)],\n",
    "                 color='r', label='confidence interval')\n",
    "plt.legend(loc = 'upper right')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Copyright &copy; 2019 The Data Incubator.  All rights reserved.*"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "nbclean": true
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
